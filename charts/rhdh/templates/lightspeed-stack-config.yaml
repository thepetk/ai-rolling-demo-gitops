kind: ConfigMap
apiVersion: v1
metadata:
  name: lightspeed-stack
  namespace: rolling-demo-ns
data:
  lightspeed-stack.yaml: |
    name: "lightspeed-core-stack"
    service:
      host: 0.0.0.0
      port: 8080
      auth_enabled: false
      workers: 1
      color_log: true
      access_log: true
    llama_stack:
      use_as_library_client: false
      url: http://localhost:8321
    user_data_collection:
      feedback_enabled: true
      feedback_storage: "/tmp/data/feedback"
    authentication:
      module: "noop"
    conversation_cache:
      type: "sqlite"
      sqlite:
        db_path: "/tmp/cache.db"
    mcp_servers:
      - name: mcp-integration-tools
        provider_id: "model-context-protocol"
        url: "http://rolling-demo-backstage.rolling-demo-ns.svc.cluster.local:7007/api/mcp-actions/v1"
    providers:
      inference:
        - provider_id: vertex_ai
          provider_type: remote::google_vertex_ai
          config:
            api_key: ${env.VLLM_API_KEY}
            url: https://generativelanguage.googleapis.com/v1/models
    models:
      - model_id: gemini-2.5-flash
        provider_id: vertex_ai
        model_type: llm
        provider_model_id: gemini-2.5-flash
